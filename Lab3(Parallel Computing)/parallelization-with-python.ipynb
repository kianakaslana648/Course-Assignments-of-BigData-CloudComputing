{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab - Parallel Processing in Python\n",
    "\n",
    "Parallel processing is a mode of operation where the task is executed simultaneously in multiple processors in the same computer. It is meant to reduce the overall processing time.\n",
    "\n",
    "However, there is usually a bit of overhead when communicating between processes which can actually increase the overall time taken for small tasks instead of decreasing it.\n",
    "\n",
    "In python, the `multiprocessing` module is used to run independent parallel processes by using subprocesses (instead of threads). It allows you to leverage multiple processors on a machine (both Windows and Unix), which means, the processes can be run in completely separate memory locations.\n",
    "\n",
    "By the end of this lab you will know:\n",
    "\n",
    "* How to structure the code and understand the syntax to enable parallel processing using `multiprocessing`\n",
    "* How to implement synchronous and asynchronous parallel processing\n",
    "* How to parallelize a `Pandas` DataFrame\n",
    "* Solve 3 different use cases with the `multiprocessing.Pool()` interface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import `multiprocessing` (you may need to install it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine the maximum number of parallel processes can you run. Note: you don't want to use all the available cores since your computer needs to process other things as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of processors:  2\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of processors: \", mp.cpu_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synchronous and Asynchronous execution\n",
    "\n",
    "In parallel processing, there are two types of execution models:\n",
    "\n",
    "* **_Synchronous_** runs the processes in the same order in which they were started. This is achieved by locking the main program until the respective processes are finished.\n",
    "\n",
    "* **_Asynchronous_**, on the other hand, doesn’t involve locking. As a result, the order of results can get mixed up but usually gets done quicker.\n",
    "\n",
    "There are 2 main objects in `multiprocessing` to implement parallel execution of a function: The `Pool` Class and the `Process` Class.\n",
    "\n",
    "### `Pool` Class\n",
    "\n",
    "* Synchronous execution\n",
    "    * `Pool.map()` and `Pool.starmap()`\n",
    "    * `Pool.apply()` not used in lab\n",
    "    \n",
    "* Asynchronous execution\n",
    "    * `Pool.map_async()` and `Pool.starmap_async()`\n",
    "    * `Pool.apply_async())` not used in lab\n",
    "\n",
    "### `Process` Class\n",
    "\n",
    "Let’s take up a typical problem and implement parallelization using the above techniques. In this lab, we stick to the `Pool` class, because it is most convenient to use and serves most common practical applications.\n",
    "\n",
    "More info on these classes [here]((https://docs.python.org/3/library/multiprocessing.html))\n",
    "\n",
    "Read about the differences between apply, map, and starmap [here](https://stackoverflow.com/questions/8533318/multiprocessing-pool-when-to-use-apply-apply-async-or-map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example\n",
    "\n",
    "Given a 2D matrix (or list of lists), count how many numbers are present between a given range in each row. We will transform a matrix into a list of rows. \n",
    "\n",
    "Import the following libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `np.randon.RandomState(100)` to set a random seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomState(MT19937) at 0x7F24F81A7D10"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.RandomState(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a large numpy array matrix of integers between 0 and 9 with 1,000,000 rows and 5 columns. You can use `np.randon.randint` for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_mat = np.random.randint(10,size=(1000000,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the array you created in the previous step to a list using `tolist()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_list = large_mat.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore your array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, 0, 2],\n",
       "       [3, 0, 9, 7, 7],\n",
       "       [6, 0, 7, 3, 5],\n",
       "       [4, 8, 4, 8, 0],\n",
       "       [8, 9, 3, 7, 4],\n",
       "       [8, 3, 1, 5, 3],\n",
       "       [4, 4, 4, 8, 3],\n",
       "       [4, 6, 6, 5, 7],\n",
       "       [3, 2, 5, 4, 3],\n",
       "       [7, 4, 1, 3, 9]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "large_mat[:10,:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that the length of your list is 1,000,000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000000"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(large_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement solution without parallelization\n",
    "\n",
    "Let’s see how long it takes to compute it without parallelization. For this, we create a function called `howmany_within_range()` and we iterate the function over every row of the matrix. Since we converted the matrix to a list, then we iterate over every element in the list. The function receives all the values on the row (list element) as input and return the count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def howmany_within_range(row, minimum, maximum):\n",
    "    \"\"\"Returns how many numbers lie within `maximum` and `minimum` in a given `row`\"\"\"\n",
    "    count = 0\n",
    "    for n in row:\n",
    "        if minimum <= n <= maximum:\n",
    "            count = count + 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterate the function `howmany_within_range` over every row in the matrix and measure the time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0777387619018555\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "## Fill in code here\n",
    "results = []\n",
    "for row in large_list:\n",
    "    results.append(howmany_within_range(row, 0, 9))\n",
    "    \n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the first 10 results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 5, 5, 5, 5, 5, 5, 5, 5, 5]\n"
     ]
    }
   ],
   "source": [
    "print(results[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that the length of results is 1,000,000 and your implementation didn't cheat!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000000"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to parallelize any function?\n",
    "\n",
    "### CAVEATS\n",
    "\n",
    "* Parallelizing a function written in the same notebook does not work on Windows. You would have to write the function in a separate script and then import it. We do not need to do that since we are in SageMaker.\n",
    "* For reasons unknown to us, `Pool.apply()` does not work on Windows or Mac M1 machines. It does work on Linux and Intel Macs. This is also fine since we are working in Linux!\n",
    "\n",
    "The general way to parallelize any operation is to take a particular function that should be run multiple times and make it run in parallel using different processors.\n",
    "\n",
    "To do this, you initialize a _Pool_ with n number of processors (or cores) and pass the function you want to parallelize to one of _Pools_ parallization methods.\n",
    "\n",
    "`multiprocessing.Pool()` provides the `apply()`, `map()` and `starmap()` methods to make any function run in parallel.\n",
    "\n",
    "Nice! So what’s the difference between `apply()` and `map()`?\n",
    "\n",
    "Both `apply` and `map` take the function to be \"parallelized\" as the main argument. But the difference is that `apply()` takes an _args_ argument that accepts the parameters passed to the _function-to-be-parallelized_ as an argument, whereas `map` can take only one _iterable_ as an argument. This is because `apply()` only runs one worker in the pool so this is not parallelization of the function, it is parallelization of a potentially larger system.\n",
    "\n",
    "So `map()` is really more suitable for simpler iterable operations and also does the job faster because it is using all of the workers in the pool.\n",
    "\n",
    "We will get to `starmap()` once we see how to parallelize `howmany_within_range()` function with `apply()` and `map()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "np.array(1000000).tolist()### Parallelizing using `Pool.map()`\n",
    "\n",
    "`Pool.map()` accepts only _one iterable as argument_. So as a workaround, we modify the `howmany_within_range` function by setting a default to the minimum and maximum parameters to create a new `howmany_within_range_rowonly()` function so it accetps only an _iterable list_ of rows as input. This is not a nice use case of map(), but it clearly shows how it differs from apply()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time 1.811729907989502\n",
      "time to set up pool 0.0309450626373291\n",
      "time to multiprocess 1.7806625366210938\n",
      "[5, 5, 5, 5, 5, 5, 5, 5, 5, 5]\n"
     ]
    }
   ],
   "source": [
    "# Parallelizing using Pool.map()\n",
    "\n",
    "# Redefine function with only 1 mandatory argument.\n",
    "def howmany_within_range_rowonly(row):\n",
    "    return howmany_within_range(row, 0, 10)\n",
    "results = []\n",
    "start = time.time()\n",
    "pool = mp.Pool(mp.cpu_count())\n",
    "\n",
    "t1 = time.time()\n",
    "## use the pool.map function\n",
    "results = pool.map(howmany_within_range_rowonly , large_list)\n",
    "t2 = time.time()\n",
    "pool.close()\n",
    "end = time.time()\n",
    "\n",
    "print('total time',end - start)\n",
    "print('time to set up pool',t1 - start)\n",
    "print('time to multiprocess',t2 - t1)\n",
    "\n",
    "\n",
    "print(results[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallelizing using `Pool.starmap()`\n",
    "\n",
    "In previous example, we have to redefine `howmany_within_range` function to make couple of parameters to take default values. Using `starmap()`, you can avoid doing this. How you ask?\n",
    "\n",
    "Like `Pool.map()`, `Pool.starmap()` also accepts only one iterable as argument, but in `starmap()`, each element in that iterable is also a iterable. You can to provide the arguments to the _function-to-be-parallelized_ in the same order in this inner iterable element, will in turn be unpacked during execution.\n",
    "\n",
    "So effectively, `Pool.starmap()` is like a version of Pool.map() that accepts arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 5, 5, 5, 5, 5, 5, 5, 5, 5]\n"
     ]
    }
   ],
   "source": [
    "# Parallelizing with Pool.starmap()\n",
    "import multiprocessing as mp\n",
    "\n",
    "pool = mp.Pool(mp.cpu_count())\n",
    "\n",
    "# use pool.starmap\n",
    "pool.starmap(howmany_within_range, [(row, 0, 10) for row in large_list])\n",
    "\n",
    "pool.close()\n",
    "\n",
    "print(results[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asynchronous Parallel Processing\n",
    "\n",
    "The asynchronous equivalents `apply_async()`, `map_async()` and `starmap_async()` lets you do execute the processes in parallel asynchronously, that is the next process can start as soon as previous one gets over without regard for the starting order. As a result, there is no guarantee that the result will be in the same order as the input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallelizing with `Pool.starmap_async()`\n",
    "\n",
    "You saw how `apply_async()` works. Can you imagine and write up an equivalent version for starmap_async and map_async? The implementation is below anyways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0), (1, 2), (2, 3), (3, 4), (4, 3), (5, 2), (6, 4), (7, 5), (8, 2), (9, 2)]\n"
     ]
    }
   ],
   "source": [
    "# Parallelizing with Pool.starmap_async()\n",
    "\n",
    "def howmany_within_range2(i, row, minimum, maximum):\n",
    "    \"\"\"Returns how many numbers lie within `maximum` and `minimum` in a given `row`\"\"\"\n",
    "    count = 0\n",
    "    for n in row:\n",
    "        if minimum <= n <= maximum:\n",
    "            count = count + 1\n",
    "    return (i, count)\n",
    "\n",
    "import multiprocessing as mp\n",
    "pool = mp.Pool(mp.cpu_count())\n",
    "\n",
    "results = []\n",
    "\n",
    "results = pool.starmap_async(howmany_within_range2, [(i, row, 4, 8) for i, row in enumerate(large_list)]).get()\n",
    "\n",
    "# With map, use `howmany_within_range_rowonly` instead\n",
    "# results = pool.map_async(howmany_within_range_rowonly, [row for row in data]).get()\n",
    "\n",
    "pool.close()\n",
    "print(results[:10])\n",
    "#> [3, 1, 4, 4, 4, 2, 1, 1, 3, 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1\n",
    "\n",
    "Use `Pool.starmap()` to get the row wise common items in list_a and list_b. Each iteration will be row_i in list_a and list_b:\n",
    "\n",
    "```\n",
    "list_a = [[1, 2, 3], [5, 6, 7, 8], [10, 11, 12], [20, 21]]\n",
    "list_b = [[2, 3, 4, 5], [6, 9, 10], [11, 12, 13, 14], [21, 24, 25]]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_a = [[1, 2, 3], [5, 6, 7, 8], [10, 11, 12], [20, 21]]\n",
    "list_b = [[2, 3, 4, 5], [6, 9, 10], [11, 12, 13, 14], [21, 24, 25]]\n",
    "temp_set = set(list_a[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2, 3], [6], [11, 12], [21]]\n"
     ]
    }
   ],
   "source": [
    "list_a = [[1, 2, 3], [5, 6, 7, 8], [10, 11, 12], [20, 21]]\n",
    "list_b = [[2, 3, 4, 5], [6, 9, 10], [11, 12, 13, 14], [21, 24, 25]]\n",
    "\n",
    "def common_items(list1, list2):\n",
    "    return list(set(list1).intersection(set(list2)))\n",
    "\n",
    "pool = mp.Pool(mp.cpu_count())\n",
    "\n",
    "prob1_answer = pool.starmap(common_items, [(list_a[i], list_b[i]) for i in range(len(list_a))])\n",
    "\n",
    "pool.close()\n",
    "\n",
    "print(prob1_answer)\n",
    "#poo.starmap()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2 \n",
    "\n",
    "You have three scripts named `script1.py`, `script2.py`, `script3.py` in your folder. Use `Pool.map()` to run each of them in parallel.\n",
    "\n",
    "You can use the function `subprocess.getstatusoutput()` that will give you the `exit code` and `stdout` from each Linux command. You know how to run a python script in Linux. Now put thoese pieces together to \"map\" a python script execution.\n",
    "\n",
    "Each script pauses and prints its name and time paused.\n",
    "\n",
    "```\n",
    "$ python script1.py \n",
    "process 1 done, slept for 2\n",
    "```\n",
    "\n",
    "We will see if the code parallelizes effectively by seeing the time taken to be less than the sum of each individual script. Do the calculation to prove it for yourself.\n",
    "\n",
    "Save your result to `prob2_answer`, which should contain the `exit code` and `stdout` from each process in a list, which is just the output from `pool.map`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['python', 'fall-2022-lab3-kianakaslana648\\\\script1.py'], returncode=2)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "pool = mp.Pool(mp.cpu_count())\n",
    "exec_cmds = [f'python script{i}.py' for i in range(1,4)]\n",
    "subprocess.getstatusoutput('python script1.py')\n",
    "\n",
    "prob2_answer = pool.starmap(subprocess.getstatusoutput, exec_cmds)\n",
    "\n",
    "pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'process 1 done, slept for 4\\n'\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 'process 1 done, slept for 4')"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3\n",
    "\n",
    "**Normalize** each row of the following 2d array (list) to vary between 0 and 1. Each row should be processed separately. That means one min/max for each row. Execute in parallel.\n",
    "\n",
    "Save your result to `prob3_answer`\n",
    "\n",
    "Read about normalization options [here](https://stats.stackexchange.com/questions/70801/how-to-normalize-data-to-0-1-range). Use the following formula:\n",
    "\n",
    "$$z_i=\\frac{x_i−min(x)}{max(x)−min(x)}$$\n",
    "\n",
    "`list_a = [[2, 3, 4, 5], [6, 9, 10, 12], [11, 12, 13, 14], [21, 24, 25, 26], [23402, 234727, 4532, 7534]]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0, 0.3333333333333333, 0.6666666666666666, 1.0], [0.0, 0.5, 0.6666666666666666, 1.0], [0.0, 0.3333333333333333, 0.6666666666666666, 1.0], [0.0, 0.6, 0.8, 1.0], [0.08197397858337496, 1.0, 0.0, 0.013041117313581964]]\n"
     ]
    }
   ],
   "source": [
    "list_aa = [[2, 3, 4, 5], [6, 9, 10, 12], [11, 12, 13, 14], [21, 24, 25, 26], [23402, 234727, 4532, 7534]]\n",
    "\n",
    "def norm_z(mylist):\n",
    "    temp_arr = np.array(mylist)\n",
    "    return ((temp_arr - temp_arr.min())/(temp_arr.max()-temp_arr.min())).tolist()\n",
    "\n",
    "pool = mp.Pool(mp.cpu_count())\n",
    "\n",
    "prob3_answer = pool.map(norm_z, [row for row in list_aa])\n",
    "\n",
    "pool.close()\n",
    "\n",
    "print(prob3_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Save your analytics results to a json object - then add, commit, and push your notebook and json to GitHub!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "json.dump({'prob1' : str(prob1_answer),\n",
    "           'prob2' : str(prob2_answer),\n",
    "           'prob3' : str(prob3_answer)\n",
    "          }, \n",
    "          fp = open('soln.json','w'))"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "nteract": {
   "version": "0.28.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
